# Full semi-synthetic training config with all available datasets
# Uses 80% for training, 20% for validation
#
# Usage: python scripts/train_semisynthetic.py --config configs/training/semisynthetic_full.yaml --device cuda

seed: 42
device: cuda
output_dir: /mnt/artifacts/project_lacuna/runs

data:
  max_rows: 128
  max_cols: 48
  
  # Training datasets (80% - 24 datasets)
  train_datasets:
    # Large datasets (>10k samples)
    - credit_card_default
    - superconductor
    - magic_telescope
    - pulsar_stars
    - avocado_prices
    - bike_sharing
    - letter_recognition
    - optical_digits
    - satellite
    - spambase
    - pendigits
    
    # Medium datasets (1k-10k samples)
    - abalone
    - cardiotocography
    - page_blocks
    - steel_plates
    - wine_quality_red
    - wine_white
    - yeast
    - concrete
    
    # Small datasets (<1k samples) - sklearn built-ins
    - breast_cancer
    - diabetes
    - wine
    - parkinsons
    - vehicle
  
  # Validation datasets (20% - 6 datasets, diverse sizes)
  val_datasets:
    - banknote
    - heart_disease
    - ionosphere
    - segmentation
    - glass
    - ecoli
    - iris

model:
  hidden_dim: 128
  evidence_dim: 64
  n_layers: 4
  n_heads: 4
  dropout: 0.1

training:
  epochs: 50
  batch_size: 16
  batches_per_epoch: 100
  val_batches: 20
  lr: 0.0003
  weight_decay: 0.01
  grad_clip: 1.0
  warmup_steps: 200
  patience: 10
  min_delta: 0.001

generator:
  n_generators: 6