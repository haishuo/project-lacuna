# Fast GPU training for iteration (~5 min)
# Usage: python scripts/train.py --config configs/training/fast_gpu.yaml

seed: 42
device: cuda
output_dir: /mnt/artifacts/project_lacuna/runs

data:
  n_range: [50, 200]
  d_range: [3, 12]
  max_cols: 16
  max_rows: 128

model:
  hidden_dim: 128
  evidence_dim: 64
  n_layers: 4
  n_heads: 4
  dropout: 0.1

training:
  epochs: 20
  batch_size: 64
  batches_per_epoch: 50
  val_batches: 10
  lr: 0.0003
  weight_decay: 0.01
  grad_clip: 1.0
  warmup_steps: 100
  patience: 5
  min_delta: 0.001

generator:
  n_generators: 6
